---
title: "Analysis of metaphoricity & creativity"
author: "Bodo Winter & Francesca Strik Lievers"
date: "19/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prelims

Load packages:

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(brms)
library(ggridges)
library(patchwork)
library(ggrepel)
```

Load experiment data:

```{r, message = FALSE, warning = FALSE}
E1 <- read_csv('../data/E1_data.csv')
E2 <- read_csv('../data/E2_data.csv')
```

Load stimulus characteristics:

```{r}
stims <- read_csv('../data/stimuli.csv')
```

For reproducibility, report R version, and brms package version:

```{r}
R.Version()$version.string
packageVersion('brms')
packageVersion('tidyverse')
packageVersion('ggridges')
packageVersion('patchwork')
```

brms settings for faster computing:

```{r}
options(mc.cores=parallel::detectCores())
```

## Data cleaning

Rename ID column to something shorter:

```{r}
E1 <- rename(E1, ID = ResponseId)
E2 <- rename(E2, ID = ResponseId)
```

This data is complete (there is no incomplete data, as otherwise it would not be moved to completed responses from Qualtrics).

Check whether exclusions need to be performed because of the catch trial. The answer was 5:

```{r}
all(E1$CatchTrial == 5)
all(E2$CatchTrial == 5)
```

Exclusions because of native speakers?

```{r}
E1 %>% count(NativeSpeaker)
E2 %>% count(NativeSpeaker)
```

Exclude:

```{r}
E2 <- filter(E2, NativeSpeaker != "No, I did not grow up speaking English at home")
```

Make into long format:

```{r}
E1
```

Check number of participants:

```{r}
nrow(E1)
nrow(E2)
```

Check number of male/female participants:

```{r}
E1 %>% count(Gender)
E2 %>% count(Gender)
```

Check age range and average age:

```{r}
mean(E1$Age)
range(E1$Age)

mean(E2$Age)
range(E2$Age)
```

## Convert to long format

Convert into long format:

```{r}
E1 <- pivot_longer(E1, Item_1:Item_50,
                   names_to = 'Item',
                   values_to = 'Response')
E2 <- pivot_longer(E2, Item_1:Item_50,
                   names_to = 'Item',
                   values_to = 'Response')
```

Make the response in an ordered variable:

```{r}
# Experiment 1:

E1 <- mutate(E1,
             Response = factor(Response,
                               levels = c('very literal', 'literal',
                                          'moderately literal', 'neutral',
                                          'moderately metaphoric', 'metaphoric',
                                          'very metaphoric')),
             ResponseNum = as.numeric(Response))

# Experiment 2:

E2 <- mutate(E2,
             Response = factor(Response,
                               levels = c('very uncreative', 'uncreative',
                                          'moderately uncreative', 'neutral',
                                          'moderately creative', 'creative',
                                          'very creative')),
             ResponseNum = as.numeric(Response))
```

Exclude straightliners. 40 times the same response is 80%, which was our pre-registered exclusion criterion. Is anybody above that?

```{r}
# Experiment 1:

E1 %>% count(ID, Response) %>% 
  filter(n >= 40)

# Experiment 2:

E2 %>% count(ID, Response) %>% 
  filter(n >= 40)
```

Merge with stimulus characteristics:

```{r}
E1 <- left_join(E1, stims, by = c('Item' = 'ID'))
E2 <- left_join(E2, stims, by = c('Item' = 'ID'))
```

Descriptive statistics, average cosine per rating. 7 = very metaphoric; 1 = very literal

```{r}
E1_means <- E1 %>% group_by(Response) %>% 
  summarize(M = mean(Cosine))
```

Descriptive statistics, average cosine per rating for experiment 2. 7 = very metaphoric; 1 = very literal

```{r}
E2_means <- E2 %>% group_by(Response) %>% 
  summarize(M = mean(Cosine))
```

Make barplots of the averages:

```{r}
# Experiment 1:

E1_barplot <- E1_means %>%
  ggplot(aes(x = factor(Response),
             y = M)) +
  geom_bar(stat = 'identity') +
  ylab('Average cosine') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        axis.title.x = element_blank())

# Experiment 2:

E2_barplot <- E2_means %>%
  ggplot(aes(x = factor(Response),
             y = M)) +
  geom_bar(stat = 'identity') +
  ylab('Average cosine') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        axis.title.x = element_blank())
```

Save both externally:

```{r}
ggsave(plot = E1_barplot, filename = '../figures/E1_barplot.pdf',
       width = 8, height = 6)
ggsave(plot = E2_barplot, filename = '../figures/E2_barplot.pdf',
       width = 8, height = 6)
```

Show them in the R script, first, Experiment 1:

```{r, fig.width = 8, fig.height = 6}
E1_barplot
```

Then, Experiment 2:

```{r, fig.width = 8, fig.height = 6}
E2_barplot
```

Round both means tables for reporting:

```{r}
E1_means <- mutate(E1_means, M = round(M, 2))
E2_means <- mutate(E2_means, M = round(M, 2))
```

Save externally:

```{r}
write_csv(E1_means, '../data/E1_means.csv')
write_csv(E2_means, '../data/E2_means.csv')
```

Make a joy plot of this:

```{r}
# Experiment 1:

E1_joy <- E1 %>% ggplot(aes(x = Cosine,
                       y = factor(Response))) +
  xlab('Cosine similarity') +
  geom_density_ridges(fill = 'steelblue', alpha = 0.8) +
  scale_x_continuous(breaks = seq(0, 1, 0.2)) +
  xlim(0, 1) +
  theme_ridges() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_text(face = 'bold'),
        axis.title.x = element_text(face = 'bold', size = 16))

# Experiment 2:

E2_joy <- E2 %>% ggplot(aes(x = Cosine,
                       y = factor(Response))) +
  xlab('Cosine similarity') +
  geom_density_ridges(fill = 'steelblue', alpha = 0.8) +
  scale_x_continuous(breaks = seq(0, 1, 0.2)) +
  xlim(0, 1) +
  theme_ridges() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_text(face = 'bold'),
        axis.title.x = element_text(face = 'bold', size = 16))
```

Show these in the script, Experiment 1:

```{r, fig.width = 8, fig.height = 6}
E1_joy
```

Experiment 2:

```{r, fig.width = 8, fig.height = 6}
E2_joy
```

Save both seperately:

```{r}
ggsave(plot = E1_joy, filename = '../figures/E1_joy_plot.pdf',
       width = 8, height = 6)
ggsave(plot = E2_joy, filename = '../figures/E2_joy_plot.pdf',
       width = 8, height = 6)
```

Put both together and save them in one:

```{r}
E1_joy <- E1_joy + ggtitle('(a) Experiment 1') +
  theme(plot.title = element_text(face = 'bold', size = 18,
                                  margin = margin(b = 20, t = 0,
                                                  r = 0, l = 0)))
E2_joy <- E2_joy + ggtitle('(b) Experiment 2') + 
  theme(plot.title = element_text(face = 'bold', size = 18,
                                  margin = margin(b = 20, t = 0,
                                                  r = 0, l = 0)))

# Put both together:

both_joy <- E1_joy + E2_joy
```

Show in script:

```{r, fig.width = 14, fig.height = 6}
both_joy
```

Save:

```{r}
ggsave(plot = both_joy, filename = '../figures/both_joy_plots.pdf',
       width = 12, height = 6)
```

## Corpus attestation descriptive stats

Check how corpus attestation influenced this:

```{r}
E1 %>% group_by(PairAttested) %>% 
  summarize(M = mean(ResponseNum),
            SD = sd(ResponseNum))
```

Recode this factor so that it becomes easier to interpret in the model (make "not attested" the reference level):

```{r}
E1 <- mutate(E1,
             PairAttested = factor(PairAttested,
                                   levels = c('not_attested', 'attested')))

E2 <- mutate(E2,
             PairAttested = factor(PairAttested,
                                   levels = c('not_attested', 'attested')))
```

## Bayesian models, Experiment 1:

Set MCMC controls for all models:

```{r}
mcmc_controls <- list(adapt_delta = 0.99, max_treedepth = 13)
```

Prior, a weakly informative prior on the slope coefficient with SD = 2 (pre-registered):

**Note Dec 13, 2022**: After acceptance of the paper, we were made aware of Lemoine (2019), and the fact that prior choices have to also be made with respect to the respective link functions, in this case the logit. It turns out that SD = 2 is actually biased towards more extreme values in probability space (0 and 1), as can be verified by `hist(plogis(rnorm(1000, 0, 2)))` compared to `hist(plogis(rnorm(1000, 0, 1)))`. We therefore chose half of the SD. The results remain qualitatively the same regardless of which SD value is chosen, and the conclusions are left untouched by this choice of priors.

```{r}
weak_prior <- prior('normal(0, 1)', class = 'b')
```

Analyze the ratings, continuous model:

```{r, message = FALSE, warning = FALSE, eval = FALSE}
E1_cont <- brm(ResponseNum ~ 1 + Cosine +
                 PairAttested + AdjFreq_log10 + NounFreq_log10 +
                 (1 + Cosine|ID) +
                 (1|Adj) + (1|Noun) + (1|Item),
               data = E1,
               family = cumulative(),
              
               prior = weak_prior,
              
               # MCMC variables:
              
               control = mcmc_controls,
               cores = 4, chains = 4,
               init = 0, seed = 42,
               warmup = 3000, iter = 5000,
               save_pars = save_pars(all = TRUE))

# Save:

save(E1_cont, file = '../models/E1_cont_mdl.Rdata',
     compress = 'xz', compression_level = 9)
```

Load:

```{r}
load('../models/E1_cont_mdl.Rdata')
```

Posterior predictive checks:

```{r, fig.width = 8, fig.height = 6}
pp_check(E1_cont, ndraws = 100)
```

Analyze the ratings, categorical model:

```{r, message = FALSE, warning = FALSE, eval = FALSE}
E1_cat <- brm(ResponseNum ~ 1 + CrossModality +
                 PairAttested + AdjFreq_log10 + NounFreq_log10 +
                 (1 + CrossModality|ID) +
                 (1|Adj) + (1|Noun) + (1|Item),
              
              data = E1,
              family = cumulative(),
              
              prior = weak_prior,
              
              # MCMC variables:
              
              control = mcmc_controls,
              cores = 4, chains = 4,
              init = 0, seed = 42,
              warmup = 3000, iter = 5000,
              save_pars = save_pars(all = TRUE))

# Save:

save(E1_cat, file = '../models/E1_cat_mdl.Rdata',
     compress = 'xz', compression_level = 9)
```

Load the models:

```{r}
load('../models/E1_cat_mdl.Rdata')
```

Posterior predictive checks:

```{r, fig.width = 8, fig.height = 6}
pp_check(E1_cat, ndraws = 100)
```

Perform LOO:

```{r eval = FALSE}
E1_cont_loo <- loo(E1_cont, moment_match = TRUE)
E1_cat_loo <- loo(E1_cat, moment_match = TRUE)

# Save:

save(E1_cont_loo, file = '../models/E1_cont_loo.Rdata',
     compress = 'xz', compression_level = 9)
save(E1_cat_loo, file = '../models/E1_cat_loo.Rdata',
     compress = 'xz', compression_level = 9)
```

Load and compare:

```{r}
load('../models/E1_cont_loo.Rdata')
load('../models/E1_cat_loo.Rdata')

# Compare:

E1_both_loo <- loo_compare(E1_cont_loo, E1_cat_loo)

# Show:

E1_both_loo
```

Check Bayes R2:

```{r}
bayes_R2(E1_cat)
bayes_R2(E1_cont)
```

Interpret the model:

```{r}
summary(E1_cont)
summary(E1_cat)
```

Check all effects:

```{r}
E1_posts <- posterior_samples(E1_cont) %>% 
  select(b_Cosine:b_NounFreq_log10)

# Extract posteriors:

b_cosine <- E1_posts$b_Cosine
b_attested <- E1_posts$b_PairAttestedattested
b_adj <- E1_posts$b_AdjFreq_log10
b_noun <- E1_posts$b_NounFreq_log10
```

Check:

```{r}
sum(b_cosine > 0) / length(b_cosine)
sum(b_attested < 0) / length(b_attested)
sum(b_adj < 0) / length(b_adj)
sum(b_noun < 0) / length(b_noun)
```

## Bayesian models, Experiment 2:

Analyze the ratings, continuous model:

```{r, message = FALSE, warning = FALSE, eval = FALSE}
E2_cont <- brm(ResponseNum ~ 1 + Cosine +
                 PairAttested + AdjFreq_log10 + NounFreq_log10 +
                 (1 + Cosine|ID) +
                 (1|Adj) + (1|Noun) + (1|Item),
               data = E2,
               family = cumulative(),
              
               prior = weak_prior,
              
               # MCMC variables:
              
               control = mcmc_controls,
               cores = 4, chains = 4,
               init = 0, seed = 42,
               warmup = 3000, iter = 5000,
               save_pars = save_pars(all = TRUE))

# Save:

save(E2_cont, file = '../models/E2_cont_mdl.Rdata',
     compress = 'xz', compression_level = 9)
```

Load:

```{r}
load('../models/E2_cont_mdl.Rdata')
```

Posterior predictive checks:

```{r, fig.width = 8, fig.height = 6}
pp_check(E2_cont, ndraws = 100)
```

Analyze the ratings, categorical model:

```{r, message = FALSE, warning = FALSE, eval = FALSE}
E2_cat <- brm(ResponseNum ~ 1 + CrossModality +
                 PairAttested + AdjFreq_log10 + NounFreq_log10 +
                 (1 + CrossModality|ID) +
                 (1|Adj) + (1|Noun) + (1|Item),
              
              data = E2,
              family = cumulative(),
              
              prior = weak_prior,
              
              # MCMC variables:
              
              control = mcmc_controls,
              cores = 4, chains = 4,
              init = 0, seed = 42,
              warmup = 3000, iter = 5000,
              save_pars = save_pars(all = TRUE))

# Save:

save(E2_cat, file = '../models/E2_cat_mdl.Rdata',
     compress = 'xz', compression_level = 9)
```

Load:

```{r}
load('../models/E2_cat_mdl.Rdata')
```


Posterior predictive checks:

```{r, fig.width = 8, fig.height = 6}
pp_check(E2_cat, ndraws = 100)
```

Perform LOO:

```{r eval = TRUE}
E2_cont_loo <- loo(E2_cont, moment_match = TRUE)
E2_cat_loo <- loo(E2_cat, moment_match = TRUE)

# Save:

save(E2_cont_loo, file = '../models/E2_cont_loo.Rdata',
     compress = 'xz', compression_level = 9)
save(E2_cat_loo, file = '../models/E2_cat_loo.Rdata',
     compress = 'xz', compression_level = 9)
```

Load and compare:

```{r}
load('../models/E2_cont_loo.Rdata')
load('../models/E2_cat_loo.Rdata')

# compare:

E2_both_loo <- loo_compare(E2_cont_loo, E2_cat_loo)

# show:

E2_both_loo
```

Check Bayes R2:

```{r}
bayes_R2(E2_cat)
bayes_R2(E2_cont)
```

Interpret the model:

```{r}
summary(E2_cont)
summary(E2_cat)
```

Check all effects:

```{r}
E2_posts <- posterior_samples(E2_cont) %>% 
  select(b_Cosine:b_NounFreq_log10)

# Extract posteriors:

b_cosine <- E2_posts$b_Cosine
b_attested <- E2_posts$b_PairAttestedattested
b_adj <- E2_posts$b_AdjFreq_log10
b_noun <- E2_posts$b_NounFreq_log10
```

Check:

```{r}
sum(b_cosine > 0) / length(b_cosine)
sum(b_attested > 0) / length(b_attested)
sum(b_adj > 0) / length(b_adj)
sum(b_noun > 0) / length(b_noun)
```


## Experiment 1 and 2, coefficient plots

Make a coefficient plot. First make both tables of posterior estimates into long format:

```{r}
# Experiment 1:

E1_posts_long <- pivot_longer(E1_posts,
                              cols = b_Cosine:b_NounFreq_log10,
                              values_to = 'Estimate',
                              names_to = 'Coefficient')

# Experiment 2:

E2_posts_long <- pivot_longer(E2_posts,
                              cols = b_Cosine:b_NounFreq_log10,
                              values_to = 'Estimate',
                              names_to = 'Coefficient')
```

Get 95% CIs:

```{r}
# Experiment 1:

E1_coefs <- E1_posts_long %>% group_by(Coefficient) %>% 
  summarize(M = mean(Estimate),
            LowerCI = quantile(Estimate, 0.025),
            UpperCI = quantile(Estimate, 0.975))

# Experiment 2:

E2_coefs <- E2_posts_long %>% group_by(Coefficient) %>% 
  summarize(M = mean(Estimate),
            LowerCI = quantile(Estimate, 0.025),
            UpperCI = quantile(Estimate, 0.975))
```

Rename the coefficients so that they are prettier for plotting:

```{r}
# Experiment 1:

E1_coefs <- mutate(E1_coefs,
                   Coefficient = ifelse(Coefficient == 'b_PairAttestedattested',
                                        'Corpus attestation', Coefficient),
                   Coefficient = ifelse(Coefficient == 'b_AdjFreq_log10',
                                        'Adjective frequency', Coefficient),
                   Coefficient = ifelse(Coefficient == 'b_NounFreq_log10',
                                        'Noun frequency', Coefficient),
                   Coefficient = ifelse(Coefficient == 'b_Cosine',
                                        'Cosine similarity', Coefficient))

# Experiment 2:

E2_coefs <- mutate(E2_coefs,
                   Coefficient = ifelse(Coefficient == 'b_PairAttestedattested',
                                        'Corpus attestation', Coefficient),
                   Coefficient = ifelse(Coefficient == 'b_AdjFreq_log10',
                                        'Adjective frequency', Coefficient),
                   Coefficient = ifelse(Coefficient == 'b_NounFreq_log10',
                                        'Noun frequency', Coefficient),
                   Coefficient = ifelse(Coefficient == 'b_Cosine',
                                        'Cosine similarity', Coefficient))
```

Plot this, Experiment 1:

```{r, fig.width = 8, fig.height = 6}
# Setting up the plot basics:

E1_coef_p <- E1_coefs %>% ggplot(aes(x = M, y = reorder(Coefficient, M),
                        xmin = LowerCI, xmax = UpperCI))

# Adding geoms:

E1_coef_p <- E1_coef_p +
  geom_point(pch = 15, size = 3) +
  geom_errorbar(width = 0.2) +
  geom_vline(xintercept = 0, linetype = 2)

# Axes:

E1_coef_p <- E1_coef_p +
  coord_cartesian(xlim = c(-5, 1)) +
  scale_x_continuous(breaks = seq(-5, 1, 1)) +
  xlab('Model coefficient') +
  ylab(NULL)

# Cosmetics:

E1_coef_p <- E1_coef_p +
  theme_classic() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(face = 'bold', size = 16,
                                    margin = margin(t = 10, b = 0,
                                                    r = 0, l = 0)),
        axis.text.y = element_text(face = 'bold', size = 14),
        axis.text.x = element_text(size = 12))

E1_coef_p
ggsave(plot = E1_coef_p, filename = '../figures/E1_coefficient_plot.pdf',
       width = 8, height = 4)
```

Plot this, Experiment 2:

```{r, fig.width = 8, fig.height = 6}
# Setting up the plot basics:

E2_coef_p <- E2_coefs %>% ggplot(aes(x = M, y = reorder(Coefficient, M),
                        xmin = LowerCI, xmax = UpperCI))

# Adding geoms:

E2_coef_p <- E2_coef_p +
  geom_point(pch = 15, size = 3) +
  geom_errorbar(width = 0.2) +
  geom_vline(xintercept = 0, linetype = 2)

# Axes:

E2_coef_p <- E2_coef_p +
  coord_cartesian(xlim = c(-3, 1)) +
  scale_x_continuous(breaks = seq(-3, 1, 1)) +
  xlab('Model coefficient') +
  ylab(NULL)

# Cosmetics:

E2_coef_p <- E2_coef_p +
  theme_classic() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(face = 'bold', size = 16,
                                    margin = margin(t = 10, b = 0,
                                                    r = 0, l = 0)),
        axis.text.y = element_text(face = 'bold', size = 14),
        axis.text.x = element_text(size = 12))

E2_coef_p
ggsave(plot = E2_coef_p, filename = '../figures/E2_coefficient_plot.pdf',
       width = 8, height = 4)
```

Put them both into the same plot:

```{r}
E1_coef_p <- E1_coef_p + ggtitle('(a) Experiment 1') +
  theme(plot.title = element_text(face = 'bold', size = 18,
                                  margin = margin(b = 20, t = 0,
                                                  r = 0, l = 0)))
E2_coef_p <- E2_coef_p + ggtitle('(b) Experiment 2') +
  theme(plot.title = element_text(face = 'bold', size = 18,
                                  margin = margin(b = 20, t = 0,
                                                  r = 0, l = 0)))

# Save:

both_coef_p <- E1_coef_p + plot_spacer() + E2_coef_p +
  plot_layout(nrow = 3, heights = c(5, 1, 5))
ggsave(plot = both_coef_p, filename = '../figures/both_coefficient_plots.pdf',
       width = 12, height = 12)
```

## Correlation between E1 and E2

Get item-based averages for E1 and E2:

```{r}
E1_items <- E1 %>% 
  group_by(Item) %>% 
  summarize(Metaphoricity = mean(ResponseNum))

E2_items <- E2 %>% 
  group_by(Item) %>% 
  summarize(Creativity = mean(ResponseNum))
```

Merge:

```{r}
both <- left_join(E1_items, E2_items)
```

Add stimulus characteristics for plotting:

```{r}
both <- left_join(both,
                  select(stims, ID, Adj, Noun), by = c('Item' = 'ID'))
```

Merge the adjective and noun pair into string for plotting:

```{r}
both <- mutate(both,
               Pair = str_c(Adj, ' ', Noun))
```

Z-scored variables for Bayesian correlation:

```{r}
both <- mutate(both,
               Met_z = Metaphoricity - mean(Metaphoricity),
               Met_z = Met_z / sd(Met_z),
               Creat_z = Creativity - mean(Creativity),
               Creat_z = Creat_z / sd(Creat_z))
```

Fit the model (no hand-specified priors here):

```{r, warning = FALSE, message = FALSE, eval = FALSE}
cor_mdl <- brm(Creat_z ~ -1 + Met_z,
               data = both)

# Save model:

save(cor_mdl, file = '../models/correlation_mdl.Rdata',
     compress = 'xz', compression_level = 9)
```

Load and summarize the models:

```{r}
# Load:

load('../models/correlation_mdl.Rdata')

# Summarize:

summary(cor_mdl)
```

Get the coefficient:

```{r}
int <- fixef(cor_mdl)[1, ]
```

Show the correlation:

```{r, fig.width = 8, fig.height = 6}
set.seed(666) # for sampling subset
both_p <- both %>% ggplot(aes(x = Metaphoricity, y = Creativity))

# Add geoms:

both_p <- both_p + 
  geom_point(alpha = 0.8, size = 3) +
  geom_text_repel(aes(label = Pair),
                  max.overlaps = Inf,
                  box.padding = 0.5,
                  min.segment.length = 0)

# Cosmetics:

both_p <- both_p +
  theme_classic() +
  theme() +
  theme(axis.title.y = element_text(face = 'bold', size = 16,
                                    margin = margin(t = 0, b = 0,
                                                    r = 10, l = 0)),
        axis.title.x = element_text(face = 'bold', size = 16,
                                    margin = margin(t = 10, b = 0,
                                                    r = 0, l = 0)),
        axis.text.y = element_text(face = 'bold', size = 14),
        axis.text.x = element_text(face = 'bold', size = 14))

# Show and save:

both_p
ggsave(plot = both_p, filename = '../figures/correlation.pdf',
       width = 8, height = 6)
```


This completes this analysis.

