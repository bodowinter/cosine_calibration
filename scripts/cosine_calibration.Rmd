---
title: "Cosine Calibration - Material selection"
author: "Bodo Winter & Francesca Strik Lievers"
date: "8/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The goal of this experiment is to see whether the cosine measure introduced by Winter (2019) reliably rpedicts metaphoricity / literalness ratings. For this, a set of words with a range of cosine values needs to be selected.

## Preprocessing:

Load packages:

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(brms)
```

Load data:

```{r, message = FALSE, warning = FALSE}
lyn <- read_csv('../data/lynott_connell_full.csv') %>% 
  select(-(Foot_leg.mean:Torso.mean), -Exclusivity.action, -Exclusivity.sensorimotor) %>% 
  rename(Excl = Exclusivity.perceptual,
         Mod = Modality)
```

Get rid of those words that have as their dominant modality interoceptive words:

```{r}
lyn <- filter(lyn, Mod != 'Interoceptive')
```

Load SUBTLEX POS tags:

```{r, message = FALSE}
SUBTL <- read.csv('../data/SUBTLEX_US_with_POS.csv',
                  stringsAsFactors = FALSE) %>%
  as_tibble() %>% 
  rename(POS = Dom_PoS_SUBTLEX) %>% 
  select(Word, POS)
```

Merge:

```{r}
lyn <- left_join(lyn, SUBTL)
```

Get nouns only:

```{r}
noun <- filter(lyn, POS == 'Noun')
```

For adjectives, we'll use the Lynott & Connell (2009) norms. These contain many more useful adjectives, as they are more specifically focused on perception (e.g., there's many auditory words such as "banging", "beeping", "squealing" that don't occur in the new Lancaster norms):

```{r, message = FALSE}
adj <- read.csv('../data/lynott_connell_2009_adj_norms.csv',
                stringsAsFactors = FALSE) %>% 
  as_tibble() %>% 
  select(-PropertyBritish) %>% 
  rename(Mod = DominantModality,
         Excl = ModalityExclusivity)
```

Get only those that are the 10% most exclusive within their perceptual modality, for adjectives, and select the 5 highest-ranking ones:

```{r}
set.seed(666)
mods <- unique(adj$Mod)
xres <- c()
for (i in seq_along(mods)) {
  this_df <- filter(adj, Mod == mods[i])
  this_df <- filter(this_df, Excl > quantile(Excl, 0.8))
  this_df <- sample_n(this_df, 5)
  xres <- bind_rows(xres, this_df)
}
```

We select 5 random ones because otherwise the touch ones will all be "aching" etc. (They are all interoceptive)

```{r}
these_words <- xres %>% pull(Word)
these_words
```

Some replacements, "tight" is shape based and quite a common sensible, and there's no texture surface descriptor in there, so let's add "smooth". "tepid" isn't known by many people, let's replace it with "warm". Let's also replace "weightless" with "hard" so that we have both roughness/smoothness and hardness/softness, the two primary dimensions of surface perception.

```{r}
these_words[these_words == 'tight'] <- 'smooth'
these_words[these_words == 'weightless'] <- 'hard'
these_words[these_words == 'tepid'] <- 'warm'
```

"Blonde" is specific to hair color, and "sunny" specific to weather:

```{r}
these_words[these_words == 'blonde'] <- 'blue'
these_words[these_words == 'sunny'] <- 'bright'
```

Replace the infrequent "tangy" with "sweet". Also, "whiffy" seems quite British and since this will be tested in America and there's no positive smell word so far:

```{r}
these_words[these_words == 'tangy'] <- 'sweet'
these_words[these_words == 'whiffy'] <- 'fragrant'
```

Replace "cooing" with "squealing":

```{r}
these_words[these_words == 'cooing'] <- 'squealing'
these_words[these_words == 'mute'] <- 'beeping'
```

Get our adjectives:

```{r}
adj <- filter(adj, Word %in% these_words)
```

Show all adjectives:

```{r}
adj %>% arrange(Mod) %>% select(Word, Mod) %>% print(n = Inf)
```


## Noun selection

For nouns we need to be a bit more selective, since most nouns are not ABOUT perceptual impressions, the same way that the adjectives from Lynott & Connell (2009) are about these. Also, we need to make sure that when the noun is combined with the adjective, it doesn't refer to an object, e.g., the sound noun "whistle", when combined with "red" could just be taken to refer to a literal whistle that is red, and not to a whistling sound.

```{r}
noun %>% arrange(desc(Visual.mean)) %>% pull(Word) %>% head(150)
```

These are the to-selected, based on that they actually describe visual impressions, and also not shape (since shape is a common sensible to many senses).

MMmhm: "Lighting" and "starlight" are good candidates as well, but they seem to come with specific assumptions (perhaps neon as well).

```{r}
vis <- c('brightness', 'color', 'gleam', 'lighting', 'vision',
         'darkness', 'glimmer', 'neon', 'starlight')
```

Same for touch:

```{r}
noun %>% arrange(desc(Haptic.mean)) %>% pull(Word) %>% head(150)
```

The problem with these is the following: There's no nouns that are specifically about touch in general (except for "touch" and "feeling", which are also highly polysemous). If we take "softness", then this will create weird mismatches, like "rough softness", which will sound metaphorical not because they combine dissimilar modalities, but because they are on opposite end of the scale of the same modality. 

We will take "touch", "feeling", and "contact" from the main data frame (they are not in the "noun" tibble since they are predominantly verbs, but since we'll present them in a nominal sentence frame, people will understand them to be nouns).

```{r}
hap <- c('touch', 'feeling', 'contact')
```

Sound nouns:

```{r}
noun %>% arrange(desc(Auditory.mean)) %>% pull(Word) %>% head(150)
```

Select these:

```{r}
aud <- c('noise', 'music', 'melody', 'harmonics', 'timbre', 'chatter', 'echo')
```

Taste:

```{r}
noun %>% arrange(desc(Gustatory.mean)) %>% pull(Word) %>% head(100)
```

Select these:

```{r}
gus <- c('flavor', 'taste')
```

Also, take "taste" from the main dataset.

Smell:

```{r}
noun %>% arrange(desc(Olfactory.mean)) %>% pull(Word) %>% head(100)
```

Select these:

```{r}
olf <- c('aroma', 'odor', 'smell', 'scent')
```

Get these nouns:

```{r}
all_senses <- c(vis, aud, hap, gus, olf)
noun <- filter(lyn, Word %in% all_senses)
```

Make the perceptual strength columns the same for both data frames:

```{r}
noun <- rename(noun,
               Aud = Auditory.mean,
               Gus = Gustatory.mean,
               Olf = Olfactory.mean,
               Hap = Haptic.mean,
               Vis = Visual.mean)
adj <- rename(adj,
               Aud = AuditoryStrengthMean,
               Gus = GustatoryStrengthMean,
               Olf = OlfactoryStrengthMean,
               Hap = HapticStrengthMean,
               Vis = VisualStrengthMean)

noun <- select(noun, Word, Excl, Mod, Vis, Aud, Hap, Gus, Olf)
adj <- select(adj, Word, Excl, Mod, Vis, Aud, Hap, Gus, Olf)
```

Create all combinations:

```{r}
adjs <- pull(adj, Word)
nouns <- pull(noun, Word)

all_combs <- expand.grid(adjs, nouns)
all_combs[, 1] <- as.character(all_combs[, 1])
all_combs[, 2] <- as.character(all_combs[, 2])
```

## Compute cosine similarity:

Define function for cosine similarity:

```{r}
cosine_sim_fast <- function(x, y) {
	as.vector((x %*% y) / (sqrt(x %*% x * y %*% y)))
	}
```

Loop through all_combs and compute cosines:

```{r}
all_cosims <- numeric(nrow(all_combs))
for (i in 1:nrow(all_combs)) {
  this_adj <- all_combs[i, 1]
  this_noun <- all_combs[i, 2]
  vector1 <- filter(adj, Word == this_adj) %>%  select(Vis:Olf) %>% unlist()
  vector2 <- filter(noun, Word == this_noun) %>% select(Vis:Olf) %>% unlist()
  all_cosims[i] <- cosine_sim_fast(vector1, vector2)
}
```

Check:

```{r}
mean(all_cosims)
range(all_cosims)
```

Make a plot of the distribution:

```{r, fig.width = 8, fig.height = 6}
hist(all_cosims, col = 'steelblue')
```

Append this to the all_combs data frame:

```{r}
colnames(all_combs) <- c('Adj', 'Noun')
all_combs$Cosine <- all_cosims
head(all_combs)
```

Append adjective and noun modality, since we want to select similar amounts per modality:

```{r}
all_combs$AdjMod <- adj[match(all_combs$Adj, adj$Word), ]$Mod
all_combs$NounMod <- lyn[match(all_combs$Noun, lyn$Word), ]$Mod
```

## Select 10 words from each cosine band (0-0.1, 0.1-0.2 etc.):

Define bands:

```{r}
bands <- seq(0, 1, 0.1)
```

Loop through:

```{r}
set.seed(42)
xall <- c()
for (i in 1:(length(bands) - 1)) {
  lb <- bands[i]
  up <- bands[i + 1]
  this_cos <- filter(all_combs, Cosine > lb, Cosine < up)
  
  # Reshuffle:
  
  this_cos <- sample_n(this_cos, size = nrow(this_cos))
  
  # Get rid of duplicats, except for bands 0.6 to 0.9 where this proves to be too exclusive:

  if (!(lb %in% bands[7:9])) {
    
  # Get rid of duplicated nouns:
  
  this_cos <- filter(this_cos, !duplicated(Noun))
  
  # Get rid of duplicated noun modalities, unless it's the band 0.6 to 0.9:
  
  this_cos <- filter(this_cos, !duplicated(NounMod))
  }
  
  # For band 0.6 to 0.9 pick 5 random ones:
  
  if (lb %in% bands[7:9]) {
    this_cos <- filter(this_cos, !duplicated(Adj))
    this_cos <- sample_n(this_cos, 5)
  }
  
  # Append:
  
  xall <- bind_rows(xall, this_cos)
}
```

Check the results:

```{r}
xall
```

The cosine bands 0.6 to 0.9 kinda suck since they are almost all the same within each band. Let's change that by hand-picking some that are different:

```{r}
xall[32, ] <- filter(all_combs, Adj == 'warm', Noun == 'taste')
xall[33, ] <- filter(all_combs, Adj == 'hard', Noun == 'color')

xall[37, ] <- filter(all_combs, Adj == 'woolly', Noun == 'vision')
xall[40, ] <- filter(all_combs, Adj == 'scaly', Noun == 'glimmer')
```

Some more hand replacements: For "contact", the social reading is quite strong. And "timbre" could easily be misunderstood as "timber", the wood, for less musically educated participants.

```{r}
# warm timbre:
xall[17, ] <- filter(all_combs, Adj == 'loud', Noun == 'color')

# beeping timbre:
xall[48, ] <- filter(all_combs, Adj == 'beeping', Noun == 'noise')

# squealing contact: 
xall[28, ] <- filter(all_combs, Adj == 'bright', Noun == 'touch')

# blue contact:
xall[35, ] <- filter(all_combs, Adj == 'smooth', Noun == 'color')
```

For the band 0.8 to 0.9 there's nothing we can do since they are all touch-touch, except for one taste-taste.

How is this distributed across noun modalities?

```{r}
table(xall$NounMod)
table(xall$AdjMod)
```

What about combinations?

```{r}
with(xall, table(AdjMod, NounMod))
```

Check that there's enough per band of cosine:

```{r}
table(cut(xall$Cosine, breaks = bands))
```

Histogram:

```{r, fig.width = 8, fig.height = 6}
hist(xall$Cosine, col = 'steelblue')
```

Make an ID variable and a "full stimulus" column (so that the entire expression can easily be copy and pasted).

```{r}
xall$ID <- str_c('Item_', 1:nrow(xall))
xall <- mutate(xall, FullStimulus = str_c(Adj, ' ', Noun))
```

Add crossmodal information to stimuli:

```{r}
xall <- mutate(xall,
               CrossModality = ifelse(AdjMod == NounMod, 'unimodal', 'crossmodal'))
```

Add hierarchy consistent/inconsistent information to stimuli:

```{r}
xall$Hierarchy <- 'inconsistent'
try(xall[xall$AdjMod == 'Haptic' & xall$NounMod == 'Gustatory', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Haptic' & xall$NounMod == 'Olfactory', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Haptic' & xall$NounMod == 'Auditory', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Haptic' & xall$NounMod == 'Visual', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Gustatory' & xall$NounMod == 'Olfactory', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Gustatory' & xall$NounMod == 'Auditory', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Gustatory' & xall$NounMod == 'Visual', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Olfactory' & xall$NounMod == 'Visual', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Olfactory' & xall$NounMod == 'Auditory', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Visual' & xall$NounMod == 'Auditory', ]$Hierarchy <- 'consistent')
try(xall[xall$AdjMod == 'Auditory' & xall$NounMod == 'Visual', ]$Hierarchy <- 'consistent')
xall[xall$CrossModality == 'unimodal', ]$Hierarchy <- NA
```

We will exchange "vision" with "sight", as it is possible to misunderstand "vision" to be about thinking about the future, or a dream.

```{r}
xall[xall$Noun == 'vision', ]$FullStimulus <- 'woolly sight'
xall[xall$Noun == 'vision', ]$Noun <- 'sight'
```

## Adding frequency information

The Corpus of Contemporary American English data is proprietary and will not be included in the repository. The adjective-noun combination frequencies come from https://www.english-corpora.org/coca/ directly and will be included in the repository since it's only 50 items:

```{r, message = FALSE, warning = FALSE}
freqs <- read_csv('../data/COCA_freq_CD.csv')

# adjective-noun pair frequencies:

pair_freqs <- read_csv('../data/COCA_frequencies.csv')
```

Get the total COCA freqs:

```{r}
freqs <- mutate(freqs,
                coca = freq_coca_spok + freq_coca_fic + freq_coca_mag +
                  freq_coca_news + freq_coca_acad)
```


We don't use lemmas here but the actual frequencies of the inflected forms, e.g., we are not interested in "beeped/beeps" but only in "beeping", which is the form used.

```{r}
xall$AdjFreq <- freqs[match(xall$Adj, freqs$w1), ]$coca
xall$NounFreq <- freqs[match(xall$Noun, freqs$w1), ]$coca
```

For adjective-noun pair frequencies, perform matching:

```{r}
pair_freqs <- mutate(pair_freqs, FullStimulus = str_c(Adj, ' ', Noun))
xall <- left_join(xall, select(pair_freqs, -Adj, -Noun),
                  by = c('FullStimulus' = 'FullStimulus'))

# Rename:

xall <- rename(xall, PairFreq = COCA_freq)
```

Log-transform the frequency variables:

```{r}
xall <- mutate(xall,
               AdjFreq_log10 = log10(AdjFreq),
               NounFreq_log10 = log10(NounFreq),
               PairFreq_log10 = log10(PairFreq + 1))
```

Create a variable that says whether it's attested or not:

```{r}
xall <- mutate(xall,
               PairAttested = ifelse(PairFreq > 0, 'attested', 'not_attested'))
```

## Analyze frequency and cosine correlation

To know whether we should control for frequency in the main analysis, we want to know whether cosines are correlated with frequencies.

brms settings for faster computing:

```{r}
options(mc.cores=parallel::detectCores())
```

With brms (only default priors). First, whether cosines are higher for attested or non-attested:

```{r, message = FALSE, warning = FALSE}
attested_mdl <- brm(Cosine ~ PairAttested +
                      (1|Adj) + (1|Noun),
                    data = xall,
                    family = Beta(),
                    
                    # MCMC variables:
                    
                    cores = 4, chains = 4,
                    init = 0, seed = 42)

raw_freq_mdl <- brm(Cosine ~ PairFreq_log10 +
                      (1|Adj) + (1|Noun),
                    data = xall,
                    family = Beta(),
                    
                    # MCMC variables:
                    cores = 4, chains = 4,
                    init = 0, seed = 42)
```

Summarize:

```{r}
summary(attested_mdl)
summary(raw_freq_mdl)
```

Posterior predictive checks for attested / not attested model:

```{r, fig.width = 8, fig.height = 6}
pp_check(attested_mdl, nsample = 100)
```

Posterior predictive checks for raw frequency model:

```{r}
pp_check(raw_freq_mdl, nsample = 100)
```

Which model performs better? R-squared:

```{r}
bayes_R2(raw_freq_mdl)
bayes_R2(attested_mdl)
```

LOO-CV:

```{r}
raw_loo <- loo(raw_freq_mdl)
attested_loo <- loo(attested_mdl)

# Compare:

both_loo <- loo_compare(raw_loo, attested_loo)
both_loo
```

Now big difference between the two, so we will use the simpler attested versus non-attested, which also makes sense given that most are not attested.

This analysis suggests that in our main model, we can go ahead with a single predictor attested versus non-attested. To compare the two models, we used Cosine as the response (so that the two models are fitted on the same data). For the paper however, it will be conceptually easier to report things in terms of corpus attestation being the response and Cosine being the predictor, given that we selected Cosines.

Prior choice:

```{r}
weak_prior <- prior('normal(0, 1)', class = 'b')
```

The model:

```{r, message = FALSE, warning = FALSE}
logistic_mdl <- brm(PairAttested ~ Cosine  +
                      (1|Adj) + (1|Noun),
                    data = xall,
                    family = bernoulli,
                    
                    prior = weak_prior,
                    
                    # MCMC variables:
                    
                    cores = 4, chains = 4,
                    init = 0, seed = 42,
                    warmup = 3000, iter = 5000,
                    control = list(adapt_delta = 0.99))
```

Posterior predictive checks:

```{r, fig.width = 8, fig.height = 6}
pp_check(logistic_mdl, nsample = 100)
```

Check:

```{r}
summary(logistic_mdl)
```

Extract the posterior probability of the effect being the opposite sign:

```{r}
slope_samples <- posterior_samples(logistic_mdl)$b_Cosine

# How many of those are not negative?

sum(slope_samples > 0) / length(slope_samples)
```

What is the average cosine for each of these?

```{r}
xall %>% group_by(PairAttested) %>% 
  summarize(M = mean(Cosine),
            SD = sd(Cosine),
            M = round(M, 2),
            SD = round(SD, 2))
```

## Finish by saving the data

Write this to file:

```{r}
write_csv(xall, '../data/stimuli.csv')
```







